Port: 8000
{
  "prediction": [
    20.35373177134412
  ]
}

NAME                                READY   STATUS    RESTARTS   AGE
udacity-project4-77dcc6b846-c5l47   1/1     Running   0          10s
Forwarding from 127.0.0.1:8000 -> 80
Forwarding from [::1]:8000 -> 80
Handling connection for 8000

$ kubectl logs udacity-project4-77dcc6b846-c5l47
 * Serving Flask app "app" (lazy loading)
 * Environment: production
   WARNING: Do not use the development server in a production environment.
   Use a production WSGI server instead.
 * Debug mode: on
 * Running on http://0.0.0.0:80/ (Press CTRL+C to quit)
 * Restarting with stat
 * Debugger is active!
 * Debugger PIN: 133-582-038
[2023-10-23 01:04:20,125] INFO in app: JSON payload:
{json_payload}
[2023-10-23 01:04:20,127] INFO in app: Inference payload DataFrame:
{inference_payload}
[2023-10-23 01:04:20,127] INFO in app: Scaling Payload:
{payload}
[2023-10-23 01:04:20,129] INFO in app: the scaled input: {scaled_payload}
[2023-10-23 01:04:20,130] INFO in app: The resultant prediction: {prediction}
127.0.0.1 - - [23/Oct/2023 01:04:20] "POST /predict HTTP/1.1" 200 -